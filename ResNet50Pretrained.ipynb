{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f179ae711ab42e59bd049f78bcddafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7293edf6c18e46b9ad73259f780e8691",
              "IPY_MODEL_94ab75c6deff4d029e0cc4dbacc321a2",
              "IPY_MODEL_337d6f9f26cf4dc19ab0ccc3e4c1a74c"
            ],
            "layout": "IPY_MODEL_f4a926b502b3492d9963b5b734c9b885"
          }
        },
        "7293edf6c18e46b9ad73259f780e8691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a94062f189164ce0aff842f95f254707",
            "placeholder": "​",
            "style": "IPY_MODEL_d632846322f5494d83a8fac34a0b1e2f",
            "value": "100%"
          }
        },
        "94ab75c6deff4d029e0cc4dbacc321a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe0ee92fc2db4175ad7d8a60832aaeab",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b42278dedd342a8b5bbe03f668e2afa",
            "value": 102530333
          }
        },
        "337d6f9f26cf4dc19ab0ccc3e4c1a74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ac9c2a2efb04effa96b9d6d18e4ca29",
            "placeholder": "​",
            "style": "IPY_MODEL_3fbbf4755c91441a82cd0a82c5968141",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 252MB/s]"
          }
        },
        "f4a926b502b3492d9963b5b734c9b885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a94062f189164ce0aff842f95f254707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d632846322f5494d83a8fac34a0b1e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe0ee92fc2db4175ad7d8a60832aaeab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b42278dedd342a8b5bbe03f668e2afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ac9c2a2efb04effa96b9d6d18e4ca29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fbbf4755c91441a82cd0a82c5968141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Images from the tar file."
      ],
      "metadata": {
        "id": "A3gECVX_QAt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLq-Mr6ZZXRU",
        "outputId": "19e2dd73-4b04-4b64-d756-2d6711ff58d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ga-fgD7M7jB"
      },
      "outputs": [],
      "source": [
        "!tar -xf /content/drive/MyDrive/Project/ip102_v1.1.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the files to store images based on the class"
      ],
      "metadata": {
        "id": "s0quaz4AP_xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# list to store the names of the image files\n",
        "train_file_names = []\n",
        "test_file_name = []\n",
        "val_file_name = []\n",
        "\n",
        "# List tostore the actual lables of each image\n",
        "train_actual_labels = []\n",
        "test_actual_labels = []\n",
        "val_actual_labels = []\n",
        "\n",
        "# Read train, test and val file to get the list of files names for each categories\n",
        "\n",
        "train_file = open(\"ip102_v1.1/train.txt\")\n",
        "for l in train_file:\n",
        "    train_file_names.append(l.split(\" \")[0])\n",
        "    train_actual_labels.append(int(l.split(\" \")[-1][:-1]))\n",
        "train_file.close()\n",
        "\n",
        "test_file = open(\"ip102_v1.1/test.txt\")\n",
        "for l in test_file:\n",
        "    test_file_name.append(l.split(\" \")[0])\n",
        "    test_actual_labels.append(int(l.split(\" \")[-1][:-1]))\n",
        "test_file.close()\n",
        "\n",
        "val_file = open(\"ip102_v1.1/val.txt\")\n",
        "for l in val_file:\n",
        "    val_file_name.append(l.split(\" \")[0])\n",
        "    val_actual_labels.append(int(l.split(\" \")[-1][:-1]))\n",
        "val_file.close()"
      ],
      "metadata": {
        "id": "XP1IJKtmN6kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the folder to store the images\n",
        "os.mkdir(\"train\")\n",
        "os.mkdir(\"test\")\n",
        "os.mkdir(\"val\")"
      ],
      "metadata": {
        "id": "sRYoA5TGOKzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating list to convert the label to actual name of categories\n",
        "super_calss = [\"Rice\",\n",
        "               \"Corn\",\n",
        "               \"Wheat\",\n",
        "               \"Beet\",\n",
        "               \"Alfalfa\",\n",
        "               \"Vitis\",\n",
        "               \"Citrus\",\n",
        "               \"Mango\"\n",
        "              ]\n",
        "super_class_count = [\n",
        "    14,13,9,8,13,16,19,10\n",
        "]"
      ],
      "metadata": {
        "id": "SaRD7mKNOMh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will continue previous process\n",
        "class_cetegories = []\n",
        "prev = 0\n",
        "for i in range(0,len(super_class_count)):\n",
        "    cl = list(range(prev,prev+super_class_count[i]))\n",
        "    class_cetegories.append(cl)\n",
        "    prev = prev + super_class_count[i]"
      ],
      "metadata": {
        "id": "Lqlfy6bKONwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is used to group classes based on their similarity or shared characteristics, such as belonging to the same type of object or activity. It is commonly used in image classification tasks to group similar classes together and improve the model's accuracy.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P4mK-NimXXG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the subclass in the train, test and val folders to store images\n",
        "for c in super_calss:\n",
        "    os.mkdir(\"train/\"+c)\n",
        "    os.mkdir(\"test/\"+c)\n",
        "    os.mkdir(\"val/\"+c)\n",
        "    \n",
        "class_cetegories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgdVplrKOOqS",
        "outputId": "a59ca6d6-49a9-4f41-a1da-f0494a0643d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
              " [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
              " [27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
              " [36, 37, 38, 39, 40, 41, 42, 43],\n",
              " [44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
              " [57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72],\n",
              " [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91],\n",
              " [92, 93, 94, 95, 96, 97, 98, 99, 100, 101]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to map the label number ot the image name\n",
        "def find_category(inp_cat):\n",
        "    for i in range(len(class_cetegories)):\n",
        "        if inp_cat in class_cetegories[i]:\n",
        "            return super_calss[i]\n",
        "        "
      ],
      "metadata": {
        "id": "jOXKTowaOyIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move images from the image folder to the train, test, and val folder\n",
        "import shutil\n",
        "root_image_folder = \"ip102_v1.1/images/\"\n",
        "\n",
        "# Following for loop to move images to the trianing folder\n",
        "for i in range(len(train_file_names)):\n",
        "    name = train_file_names[i]\n",
        "    label = train_actual_labels[i]\n",
        "    subfolder = find_category(label)  \n",
        "    shutil.move(root_image_folder+name,\"train/\"+subfolder+\"/\"+name)\n",
        "    # shutil.move(\"train/\"+subfolder+\"/\"+name,\"val/\"+subfolder+\"/\"+name)\n",
        "\n",
        "# Following for loop is to move image to the test folder\n",
        "for i in range(len(test_file_name)):\n",
        "    name = test_file_name[i]\n",
        "    label = test_actual_labels[i]\n",
        "    subfolder = find_category(label)\n",
        "    shutil.move(root_image_folder+name,\"test/\"+subfolder+\"/\"+name)\n",
        "    # shutil.move(\"test/\"+subfolder+\"/\"+name,\"val/\"+subfolder+\"/\"+name)\n",
        "\n",
        "# Folloing for loop is to move images to the validation folder\n",
        "for i in range(len(val_file_name)):\n",
        "    name = val_file_name[i]\n",
        "    label = val_actual_labels[i]\n",
        "    subfolder = find_category(label)\n",
        "    shutil.move(root_image_folder+name,\"val/\"+subfolder+\"/\"+name)\n",
        "    # shutil.move(\"val/\"+subfolder+\"/\"+name,\"val/\"+subfolder+\"/\"+name)"
      ],
      "metadata": {
        "id": "V1QP2CkVOPsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(inputs):\n",
        "     noise = torch.randn_like(inputs)*0.2\n",
        "     return inputs + noise"
      ],
      "metadata": {
        "id": "Kq5acStXPIVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "c83YArOJREXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install barbar\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "from distutils.util import strtobool\n",
        "from barbar import Bar\n",
        "import copy\n",
        "import time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALw4_ZgDPU2b",
        "outputId": "c2534038-412f-4f1d-b1de-7e9badf7ccb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting barbar\n",
            "  Downloading barbar-0.2.1-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: barbar\n",
            "Successfully installed barbar-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50 Pretrained Model"
      ],
      "metadata": {
        "id": "14LMFTXcRQVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pretrained ResNet50 Model\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "\n",
        "\n",
        "dropout = 0.5\n",
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "# Add new layer to make it to classify for 8 super class\n",
        "model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(num_ftrs, 8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "0f179ae711ab42e59bd049f78bcddafe",
            "7293edf6c18e46b9ad73259f780e8691",
            "94ab75c6deff4d029e0cc4dbacc321a2",
            "337d6f9f26cf4dc19ab0ccc3e4c1a74c",
            "f4a926b502b3492d9963b5b734c9b885",
            "a94062f189164ce0aff842f95f254707",
            "d632846322f5494d83a8fac34a0b1e2f",
            "fe0ee92fc2db4175ad7d8a60832aaeab",
            "7b42278dedd342a8b5bbe03f668e2afa",
            "1ac9c2a2efb04effa96b9d6d18e4ca29",
            "3fbbf4755c91441a82cd0a82c5968141"
          ]
        },
        "id": "DZ3eJntZRQxb",
        "outputId": "3c9ddd95-b4c9-4145-c676-0f7406157fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f179ae711ab42e59bd049f78bcddafe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Image Data"
      ],
      "metadata": {
        "id": "p2nvSZFNRUhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following is the image loader\n",
        "input_size = 224\n",
        "# Following is the data augmentation Which will be applied during the training\n",
        "data_transforms = {\n",
        "            'train': transforms.Compose([\n",
        "               transforms.Resize(256),\n",
        "               transforms.AugMix(),\n",
        "                transforms.RandomCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "        }\n",
        "\n",
        "\n",
        "# Following is the dataset loader to save the memoery\n",
        "batch_size = 64  # Can  be adjusted based on the available ram\n",
        "\n",
        "train_folder = \"train/\" # Training Folder\n",
        "val_folder = \"val/\"  # Validation Data Folder\n",
        "\n",
        "train_set = ImageFolder(root= train_folder, transform= data_transforms['train'])\n",
        "valid_set = ImageFolder(root= val_folder, transform= data_transforms['val'])\n",
        "\n",
        "# Following is data generator defining the batch size\n",
        "train_set = DataLoader(train_set, batch_size= batch_size, shuffle= True, \n",
        "                            num_workers= 8, pin_memory=True)\n",
        "valid_set = DataLoader(valid_set, batch_size= batch_size, shuffle= False, \n",
        "                                num_workers= 8, pin_memory= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_bC-ti4RR4D",
        "outputId": "831b00fa-3f51-4953-de77-5eb4e239ddec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9D7H_pz8RWvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the model for the trianing"
      ],
      "metadata": {
        "id": "MIcflwZLRacc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following is the model training procedure\n",
        "val_acc_history = []\n",
        "train_acc_history = []\n",
        "val_loss_history = []\n",
        "train_loss_history = []\n",
        "\n",
        "\n",
        "device = \"cuda\"\n",
        "model = model.to(device)\n",
        "weight_decay =  0.00001\n",
        "dataloaders = {'train': train_set, 'val': valid_set}\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "params_to_update = model.parameters()\n",
        "optimizer_ft = optim.Adam(params_to_update, lr= 0.0001, betas= (0.9, 0.999),\n",
        "                                eps= 1e-08, weight_decay= weight_decay)\n",
        "\n"
      ],
      "metadata": {
        "id": "SlwlCfYxRdm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training The model using the for loop method"
      ],
      "metadata": {
        "id": "h6XSG-5FRgOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma= 0.96)\n",
        "optimizer = optimizer_ft\n",
        "num_epochs = 5\n",
        "is_save_checkpoint = False\n",
        "is_inception = False\n",
        "ckpepoch = 0\n",
        "since = time.time()\n",
        "best_acc = 0.0\n",
        "\n",
        "# Following are the epochs loop of the training \n",
        "for epoch in range(ckpepoch, num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for data in Bar(dataloaders[phase]):\n",
        "            if len(data) > 2:\n",
        "                inputs, _ , labels = data\n",
        "                inputs = add_noise(inputs)\n",
        "                inputs = inputs.to(device)\n",
        "            else:\n",
        "                inputs, labels = data\n",
        "                inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                if is_inception and phase == 'train':\n",
        "                    outputs, aux_outputs = model(inputs)\n",
        "                    loss1 = criterion(outputs, labels)\n",
        "                    loss2 = criterion(aux_outputs, labels)\n",
        "                    loss = loss1 + 0.4*loss2\n",
        "                else:\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if is_save_checkpoint:\n",
        "                torch.save(model.state_dict(), \"/content/drive/MyDrive/Project/\"+\"resnet50pretrainedSuperModel_100\")\n",
        "                # torch.save({'epoch': epoch,\n",
        "                #         'model_state_dict': model.state_dict(),\n",
        "                #         'optimizer_state_dict': optimizer.state_dict(),\n",
        "                #         'best_acc': best_acc,\n",
        "                #         'scheduler_state_dict': scheduler.state_dict(),\n",
        "                #         }, checkpointFn)\n",
        "\n",
        "            count2stop = 0\n",
        "\n",
        "        elif phase == 'val':\n",
        "            count2stop += 1\n",
        "\n",
        "        if phase == 'val':\n",
        "            val_loss_history.append(epoch_loss)\n",
        "            val_acc_history.append(epoch_acc)\n",
        "        if phase == 'train':\n",
        "            train_loss_history.append(epoch_loss)\n",
        "            train_acc_history.append(epoch_acc)\n",
        "\n",
        "\n",
        "    if count2stop == 10:\n",
        "        break\n",
        "\n",
        "    if scheduler:\n",
        "        scheduler.step()\n",
        "        print('lr :', scheduler.get_lr())\n",
        "\n",
        "    print()\n",
        "\n",
        "time_elapsed = time.time() - since\n",
        "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "model.load_state_dict(best_model_wts)\n",
        "his = {'train_loss': train_loss_history,\n",
        "       'train_acc': train_acc_history,\n",
        "       'val_loss': val_loss_history,\n",
        "       'val_acc': val_acc_history}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNk9ULXxRd3o",
        "outputId": "b9601773-c408-4bf2-a7c5-f0e57c0e2012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "45095/45095: [===============================>] - ETA 12.5s\n",
            "train Loss: 0.9350 Acc: 0.6791\n",
            "7508/7508: [===============================>] - ETA 5.0s\n",
            "val Loss: 0.8076 Acc: 0.7207\n",
            "lr : [9.216e-05]\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:587: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45095/45095: [===============================>] - ETA 13.7s\n",
            "train Loss: 0.7862 Acc: 0.7311\n",
            "7508/7508: [===============================>] - ETA 6.4s\n",
            "val Loss: 0.8001 Acc: 0.7344\n",
            "lr : [8.847359999999999e-05]\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "45095/45095: [===============================>] - ETA 12.0s\n",
            "train Loss: 0.6709 Acc: 0.7698\n",
            "7508/7508: [===============================>] - ETA 4.6s\n",
            "val Loss: 0.7557 Acc: 0.7525\n",
            "lr : [8.493465599999999e-05]\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "45095/45095: [===============================>] - ETA 13.5s\n",
            "train Loss: 0.5932 Acc: 0.8000\n",
            "7508/7508: [===============================>] - ETA 5.3s\n",
            "val Loss: 0.7366 Acc: 0.7572\n",
            "lr : [8.153726975999998e-05]\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "45095/45095: [===============================>] - ETA 14.7s\n",
            "train Loss: 0.5241 Acc: 0.8223\n",
            "7508/7508: [===============================>] - ETA 5.1s\n",
            "val Loss: 0.7377 Acc: 0.7686\n",
            "lr : [7.827577896959998e-05]\n",
            "\n",
            "Training complete in 101m 36s\n",
            "Best val Acc: 0.768647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3fSGDADVWDZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Project/\"+\"resnet50pretrainedSuperModel_8_with_noise\")"
      ],
      "metadata": {
        "id": "t-xClNS8Rkbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Az_aLfNSGZtU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}